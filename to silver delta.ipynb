{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9228ff60-e1c1-4907-85ba-451c651675c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n📥 Reading from: abfss://bronze@ahmedolympicsdatalake.dfs.core.windows.net/coaches/\n💾 Writing to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/coaches/ as Delta with schema overwrite\n✅ Delta written to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/coaches/\n🗃️ Registering (or replacing) table in Unity Catalog: olympics.silver.coaches\n✅ Table registered successfully: olympics.silver.coaches\n\n📥 Reading from: abfss://bronze@ahmedolympicsdatalake.dfs.core.windows.net/athletes/\n💾 Writing to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/athletes/ as Delta with schema overwrite\n✅ Delta written to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/athletes/\n🗃️ Registering (or replacing) table in Unity Catalog: olympics.silver.athletes\n✅ Table registered successfully: olympics.silver.athletes\n\n📥 Reading from: abfss://bronze@ahmedolympicsdatalake.dfs.core.windows.net/events/\n💾 Writing to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/events/ as Delta with schema overwrite\n✅ Delta written to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/events/\n🗃️ Registering (or replacing) table in Unity Catalog: olympics.silver.events\n✅ Table registered successfully: olympics.silver.events\n\n📥 Reading from: abfss://bronze@ahmedolympicsdatalake.dfs.core.windows.net/nocs/\n💾 Writing to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/nocs/ as Delta with schema overwrite\n✅ Delta written to: abfss://silver@ahmedolympicsdatalake.dfs.core.windows.net/nocs/\n🗃️ Registering (or replacing) table in Unity Catalog: olympics.silver.nocs\n✅ Table registered successfully: olympics.silver.nocs\n"
     ]
    }
   ],
   "source": [
    "def convert_parquet_to_delta_and_register(datasets: list, catalog: str = \"olympics\", schema: str = \"silver\"):\n",
    "    \"\"\"\n",
    "    Reads Parquet files from source_container/folder, writes them as Delta\n",
    "    to destination_container/folder, and registers them as external tables in Unity Catalog.\n",
    "    Overwrites existing tables and schema.\n",
    "\n",
    "    Args:\n",
    "        datasets (list): List of dictionaries with keys:\n",
    "                         - folder: name of the folder (subpath)\n",
    "                         - source: name of the source container (e.g., bronze)\n",
    "                         - destination: name of the destination container (e.g., silver)\n",
    "        catalog (str): Unity Catalog name\n",
    "        schema (str): Unity Catalog schema name\n",
    "    \"\"\"\n",
    "    for dataset in datasets:\n",
    "        folder = dataset[\"folder\"]\n",
    "        source_container = dataset[\"source\"]\n",
    "        destination_container = dataset[\"destination\"]\n",
    "\n",
    "        source_path = f\"abfss://{source_container}@ahmedolympicsdatalake.dfs.core.windows.net/{folder}/\"\n",
    "        destination_path = f\"abfss://{destination_container}@ahmedolympicsdatalake.dfs.core.windows.net/{folder}/\"\n",
    "        table_name = folder.lower()\n",
    "        full_table_name = f\"{catalog}.{schema}.{table_name}\"\n",
    "\n",
    "        print(f\"\\n📥 Reading from: {source_path}\")\n",
    "        try:\n",
    "            df = spark.read.parquet(source_path)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading from {source_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"💾 Writing to: {destination_path} as Delta with schema overwrite\")\n",
    "        try:\n",
    "            df.write.format(\"delta\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .option(\"overwriteSchema\", \"true\")\\\n",
    "                .save(destination_path)\n",
    "            print(f\"✅ Delta written to: {destination_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error writing Delta to {destination_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"🗃️ Registering (or replacing) table in Unity Catalog: {full_table_name}\")\n",
    "        try:\n",
    "            spark.sql(f\"DROP TABLE IF EXISTS {full_table_name}\")\n",
    "            spark.sql(f\"\"\"\n",
    "                CREATE TABLE {full_table_name}\n",
    "                USING DELTA\n",
    "                LOCATION '{destination_path}'\n",
    "            \"\"\")\n",
    "            print(f\"✅ Table registered successfully: {full_table_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error registering table {full_table_name}: {e}\")\n",
    "my_datasets = [\n",
    "    {\"folder\": \"coaches\", \"source\": \"bronze\", \"destination\": \"silver\"},\n",
    "    {\"folder\": \"athletes\", \"source\": \"bronze\", \"destination\": \"silver\"},\n",
    "    {\"folder\": \"events\", \"source\": \"bronze\", \"destination\": \"silver\"},\n",
    "    {\"folder\": \"nocs\", \"source\": \"bronze\", \"destination\": \"silver\"}\n",
    "]\n",
    "\n",
    "convert_parquet_to_delta_and_register(my_datasets)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "to silver delta",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}